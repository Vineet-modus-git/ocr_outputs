commitment to a sustainable energy future, making it an attractive market for data centers aiming to achieve net zero operations. SISL's long-term goal of net zero, is an example of growing interest in renewable energy in the Indian data center industry.

### 1.8.2 Enhancing data center performance with high-speed and sustainable connectivity

With growing demands from AI, IoT, and edge computing, data centers need fast, low-latency connectivity for real-time processing and reliable performance. In India, tech giants are responding with major infrastructure investments. Meta is investing USD 10 billion in a 500 Tbps submarine cable, while Google is launching its USD 400 million Blue-Raman system in India. Fiber-optic networks, 5G, and submarine cables enable ultra-fast communication, boosting agility and reducing downtime.

Beyond speed, improved connectivity supports sustainability by enabling real-time monitoring, energy optimization, and smarter grid use, cutting power waste and inefficiencies. As data centers grow, connectivity upgrades must align with resilience and energy-efficiency goals.

### 1.8.3 Increasing power requirements on account of GPUs

Graphics Processing Units (GPUs) are now central to modern computing, especially in AI, data analytics, and high-performance computing. Unlike CPUs, GPUs handle massive parallel workloads, making them vital for training large AI models and managing complex data.

India's plan to deploy 18,000 high-end GPU-based facilities (under IndiaAI Mission), announced by the Union IT Minister during early Q4 of Fiscal 2025, will significantly raise power demand in the data center sector. GPUs consume far more power than CPUs, driving the need for stronger power infrastructure.

To support these energy-intensive systems, data centers must invest in reliable power supplies and advanced cooling to prevent overheating. This shift highlights a key trend: growing focus on energy-efficient and sustainable practices. As AI adoption grows, the data center industry will evolve with innovative solutions to meet the rising power needs of GPU-centric operations.

### 1.8.4 Making data centers AI-ready: infrastructure, efficiency and sustainability

As AI becomes central to business and technology operations, data centers must evolve to support the high computational demands of AI workloads. These require specialized hardware such as NVIDIA H100/H200/GB200 Tensor Core GPUs, AMD Instinct MI300 accelerators, Google TPUs (v4 and v5), and custom ASICs developed for large-scale deep learning and inference tasks. These chips offer massive parallelism, high memory bandwidth, and tensor processing capabilities tailored for training foundation models and running inference at scale. Major data center players such as SISL, CtrlS, and STT GDC India have invested in upgrading their infrastructure to support AI workloads.

AI workloads are expected to increase rack density extensively (from a global average of 12 kW per rack in calendar year 2024), often requiring power-dense setups ranging from 80–120 kW per rack for training Large Language Models (LLMs) and 10–20 kW per rack for inference. This surge in density necessitates advanced power and thermal management systems.

To manage the heat produced by densely packed AI clusters, advanced cooling technologies like liquid cooling, rear door heat exchangers (RDHx), and immersion cooling are being adopted over traditional air cooling. These systems not only prevent thermal throttling (a process where a processor reduces its performance to avoid overheating) but also improve energy efficiency in AI-dense environments.

Scalability is another critical requirement where data centers need low-latency, high-throughput networking solutions to enable rapid communication between thousands of GPUs in distributed training setups. Efficient orchestration platforms like Kubernetes with AI-specific extensions help schedule workloads dynamically and optimize resource usage.

On the sustainability front, powering AI infrastructure with renewable energy sources and implementing AI-driven energy optimization tools can significantly lower the carbon footprint. AI itself is being leveraged within data centers for predictive maintenance, dynamic workload scheduling, and real-time cooling control, making the infrastructure not just AI-capable (able to run AI workloads) but also AI-enhanced (using AI to improve its own efficiency and performance).

## 2. Data center operational aspects

A data center is a purpose-built facility designed to host critical IT infrastructure including servers, storage systems, racks, and networking equipment enabling secure data processing, storage, and connectivity for enterprises and digital platforms. Constructing a data center involves specialized design considerations including high load-bearing floors, raised flooring for cable management, precision cooling systems, fire suppression, and robust power backup